I.技术要求
 注：“▲”所标参数为专家进行综合评分的重要参数，但不作为废标条款。

序号	货物名称	技术指标（包括技术标准、技术规格等）	数量	计量单位	备注
1	GPU计算服务器
1.1	中央处理器	（1）16核32线程，保证可以足够带动服务器的基本框架。
（2）1500GB最大内存容量，保证能多线程处理大量信息。使得队列中的数据能进入所需要的模型中进行计算。	2	套	
1.2	显卡	（1）应具有强大的并行计算能力，专门用于处理需要强大计算能力支持的密集型HPC、AI和图形处理任务。
（2）采用针对学习优化的流式多处理器架构。最新一代的流式多处理架构，在同样的功率范围内可以大幅提升 FP32（单精度浮点）和 FP64（双精度浮点）的运算性能。专为深度学习设计的全新 Tensor Core 在模型训练场景中，处理神经网络的最佳选择是tensor core，所以显卡的最重要的特征是要有充足的tensor核心，最高可以达到 12 倍速的 TFLOP（每秒万亿次浮点运算）。
峰值运算性能应如下所示：
双精度浮点（FP64）运算性能：7.5 TFLOP/s；
单精度（FP32）运算性能：15 TFLOP/s;
混合精度矩阵乘法和累加：120 Tensor TFLOP/s。
（3）在通用计算工作负载中的能效提高50%
（4）L1数据缓存性能大幅提升. 将数据缓存和共享内存功能整合进单一内存块中，可为两种类型内存访问提供出色的整体性能，带来更低延迟和更高带宽。整合后的容量可达128KB/SM，比GP100数据缓存大了七倍以上，不使用共享内存的程序可将其作为缓存，纹理单元也可使用该缓存。
（5）新增SIMT线程模型，可消除之前的SIMT和SIMD处理器设计中存在的限制。
（6）选取至少8块GPU并行计算，其数量一定要有保证。当训练样本只有百万级别的时候，单卡GPU就可以满足，但训练数量达到上千万的时候，单卡训练消耗时间很长，这时候要采用数据并行化或者模型并行化加速。所以显卡的数量要有保证。	8	套	▲
1.3	网卡	（1）10000Mbps以上的传输速率。传输速率要能达到10000Mbp，可从因特网下载大量的文件，并且可以与普通计算机进行交互，使得数据传输的时间大大减少，增加效率。另外网卡能够从标准和低配置的PCIe槽和服务器中获得更高的带宽和吞吐量；
（2）当使用微软*或可伸缩的I / O在Linux *上的接收端扩展时，通过高效地平衡CPU核心的网络负载，提高多处理器系统的性能。
（3）PCI-X总线。它与原来的PCI相比在I/O速度方面提高了一倍，比PCI接口具有更快的数据传输速度（2.0版本最高可达到266MB/s的传输速率）。	1 	套	▲
1.4	内存条	内存是深度学习模型能否在服务器上运行比较重要的因素。深度学习模型除了需要很大的计算性能以外，还需要其能保证多计算完全可以在服务器端能运行。
需要的内存要求为：
1）	DDR4 ：16bit预取机制（DDR3为8bit），同样内核频率下理论速度是DDR3的两倍；更可靠的传输规范，数据可靠性进一步提升；工作电压降为1.2V，更节能。
2）	8*32GB 可以允许至少16个深度学习模型在服务器上同时并行，这样可以使计算大大加快。	8	套	▲
1.5	固态硬盘	服务器应具有足够的空间，使得之前的运算能完整保存在上面。且需要有很大的读取速度。
（1）内存要求：4*2TB 足够能让服务器存储巨大的模型
（2）持续读写速度：500MB/Sec 持续读写速度有保障的前提下，系统出错误的概率也会大大降低。
（3）随机读写速度，可以达到0.1毫秒或者更低，达到极低的存取时间。
（4）工作温度范围要有保证。普通固态硬盘一般工作的温度为50摄氏度，而考虑到服务器多显卡工作，需要保证工作温度更高，达到70-100摄氏度的级别。	4	只	
1.6	阵列卡	阵列卡可以把若干硬磁盘驱动器按照一定要求组成一个整体，整个磁盘阵列由阵列控制器管理。阵列卡的需求：
（1）：数据传输速率：6Gb/s。多台磁盘驱动器可以并行工作，可以提高传输效率；提供校验和冗余,提高了数据的安全性。

（2）要大大提高存储容量，可连接多达 256个 SATA 和/或 SAS 器件。
（3）具备可恢复热备件支持功能的全局和专用热备件；针对 SAS 阵列的紧急 SATA 热备件；统一的控制器多路径（故障转移）；I/O 负载均衡；综合而全面的 RAID 管理套件。RAID技术要提供比通常的磁盘存储更高的性能指标、数据完整性和数据可用性。尤其是在当今面临的I/O总是滞后于CPU性能的瓶颈问题越来越突出的情况下，RAID解决方案能够有效地弥补这个缺口。	1 	套	▲




